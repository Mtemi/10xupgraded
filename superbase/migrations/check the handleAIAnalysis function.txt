check the handleAIAnalysis function on the EditorPanel.tsx and tell me if after clicking start analysis button on the LiveTradingAIDialog , what happens? because we need to feed these live logs as they come in, we need to send them to AI, same AI and we need to automatically post these on the chat that generated the file, and wait for AI to give response , after response, based on the number of Iterations, we should send another logs immediately they fill the chunk size as selected by the user , send this new chunk as well until we exhaust the iterations selected by the user, then immediately we get the AI anthropic response of the last chunk response, of course it means new improved trading script/file has been generated, and so since the current file generating the logs is still running, user will get a status update next to the : "Live Trade with AI" whose statuse could be : "AI improved version available" such that users can click on the "AI improved version available" status and view the most recent and newest file/script that now users can be able to run using the available run function. so basically now , when I click : "start analysis" button, yes, I see processing , but the action should pick the logs automatically when they fill the chunk size, send that via the chat messaging available and is good user can see the logs that were posted to the chart on the chat function , of course this need to utilise user's tokens .


Confirm below if the key changes and features are implemented:

real-time log processing:

Maintains a buffer of logs until reaching the chunk size
Processes chunks automatically as they come in
Uses WebSocket connection to receive new logs
Integrated with chat interface:

Sends logs to AI through the chat API
Streams responses back
Shows analysis in the chat interface
Added token management:

Estimates token usage before processing
Checks token availability
Tracks token usage after processing
Improved version handling:

Creates new files with timestamp suffixes
Updates status to show when improved versions are available
Allows users to access improved versions
Status management:

Shows processing status
Handles iterations counting
Provides feedback through toast notifications
To use this:

Click "Live Trade with AI" button
Configure chunk size and iterations
Start analysis
The system will:
Collect logs until reaching chunk size
Send to AI for analysis
Create improved versions
Continue until iterations complete
Show status updates and new file availability
The improved versions will be available through the status indicator and file system, allowing users to easily switch between versions and compare improvements.

confirm if below function is looking good the all above requirements .  

const handleAIAnalysis = async (config: { chunkSize: number; iterations: number; customInstructions: string }) => {
      if (!selectedFile || !editorDocument) {
        toast.error('No file selected');
        return;
      }
   
      setIsProcessingAI(true);
      let iterationCount = 0;
      let logBuffer: string[] = [];
   
      try {
        const { data: { user } } = await supabase.auth.getUser();
        if (!user) {
          toast.error('Please sign in to use AI analysis');
          return;
        }
   
        // Get current file content
        const currentFile = workbenchStore.files.get()[selectedFile];
        if (!currentFile || currentFile.type !== 'file') {
          throw new Error('Invalid file');
        }
   
        // Function to process a chunk of logs
        const processLogChunk = async (chunk: string[]) => {
          try {
            // Estimate token usage
            const promptText = `
              Analyze these trading bot execution logs and suggest improvements:
   
              Current Script:
              \`\`\`python
              ${currentFile.content}
              \`\`\`
   
              Recent Logs:
              \`\`\`
              ${chunk.join('\n')}
              \`\`\`
   
              ${config.customInstructions ? `Additional Instructions: ${config.customInstructions}\n` : ''}
   
              Please:
              1. Analyze the trading performance and errors
              2. Suggest specific improvements
              3. Provide an improved version of the script
            `;
   
            const estimatedTokens = await estimateTokens(promptText);
            const hasTokens = await checkTokenAvailability(user.id, estimatedTokens);
           
            if (!hasTokens) {
              throw new Error('Insufficient tokens');
            }
   
            // Send to chat interface
            const messages = [{
              role: 'user' as const,
              content: promptText
            }];
   
            // Track token usage
            await trackTokenUsage(user.id, estimatedTokens, 'script_generation');
   
            // Send to chat and get streaming response
            const response = await fetch('/api/chat', {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({ messages })
            });
   
            if (!response.ok) {
              throw new Error('Failed to get AI analysis');
            }
   
            // Process streaming response
            const reader = response.body?.getReader();
            let analysisResult = '';
   
            if (reader) {
              while (true) {
                const { done, value } = await reader.read();
                if (done) break;
                const text = new TextDecoder().decode(value);
                analysisResult += text;
   
                // Update chat interface in real-time
                chatStore.setKey('messages', [...chatStore.get().messages, {
                  role: 'assistant',
                  content: text
                }]);
              }
            }
   
            // Extract and save improved script
            const improvedScript = extractScriptFromResponse(analysisResult);
            if (improvedScript) {
              const timestamp = Date.now();
              const baseName = selectedFile.split('/').pop()?.replace('.py', '') || 'script';
              const newFileName = `${baseName}_improved_${timestamp}.py`;
             
              await workbenchStore.saveFile(`/home/project/${newFileName}`, improvedScript);
             
              // Update status to show improved version is available
              setNotebookStatuses(prev => ({
                ...prev,
                [currentFileName]: {
                  ...prev[currentFileName],
                  improvedVersion: newFileName
                }
              }));
   
              toast.success('New improved version available');
            }
   
            iterationCount++;
           
            // Check if we should continue
            if (config.iterations !== -1 && iterationCount >= config.iterations) {
              setIsProcessingAI(false);
              setShowAIDialog(false);
              toast.success('AI analysis complete');
            }
   
          } catch (error) {
            console.error('Error processing log chunk:', error);
            toast.error(error.message || 'Failed to process log chunk');
            setIsProcessingAI(false);
          }
        };
   
        // Set up log processing
        const handleNewLog = (log: string) => {
          logBuffer.push(log);
         
          if (logBuffer.length >= config.chunkSize) {
            const chunk = [...logBuffer];
            logBuffer = []; // Clear buffer
            processLogChunk(chunk);
          }
        };
   
        // Subscribe to new logs
        socket.on('execution_log', (data: { notebook_name: string; output: string }) => {
          if (data.notebook_name === currentFileName) {
            handleNewLog(data.output);
          }
        });
   
        // Process any existing logs if available
        if (logs.length >= config.chunkSize) {
          const initialChunk = logs.slice(-config.chunkSize);
          processLogChunk(initialChunk);
        }
   
      } catch (error) {
        console.error('Error in AI analysis:', error);
        toast.error('Failed to start AI analysis');
        setIsProcessingAI(false);
      }
    };


confirm that the The implementation correctly:

Collects logs until reaching the specified chunk size
Processes each chunk through AI analysis
Updates the chat interface in real-time
Creates and saves improved versions
Manages iterations and status
Handles token usage and validation
Provides user feedback through toast notifications